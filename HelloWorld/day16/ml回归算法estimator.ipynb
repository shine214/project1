{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-11T05:42:05.806986Z",
     "start_time": "2025-01-11T05:42:05.065127Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, Ridge, LogisticRegression, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, classification_report, roc_auc_score\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 回归算法 1.线性回归（正规方程版） LinearRegression()",
   "id": "99c8ca44577d761f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "    正规方程通过二次型直接求解，速度快，适用于小型数据，大数据的话时间复杂度O(m3)太大了\n",
    "    正规方程版线性回归就是 y = k1x1 + k2x2 + k3x3 + b\n",
    "    其中x是每个特征的参数值，k是每个特征对于结果的权重，b是偏置值，y即为最终的预测目标\n",
    "    这里使用b就是为了防止该函数被迫通过原点（因为在某些情况不见得参数为0结果就是0）\n",
    "    \n",
    "    它内部找最小值的办法\n",
    "    线性回归有一个直接求解的方法，称为 正规方程（Normal Equation）（二次型）。通过数学推导，它可以直接找到使 MSE 最小化的参数：\n",
    "    \n",
    "    \n",
    "    评估线性回归的指标\n",
    "\"\"\""
   ],
   "id": "4946b4ec6fad0d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T05:45:08.361908Z",
     "start_time": "2025-01-11T05:45:08.348832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "线性回归直接预测房子价格\n",
    ":return: None\n",
    "\"\"\"\n",
    "# 获取数据\n",
    "fe_cal = fetch_california_housing(data_home='../python_ml/data')\n",
    "\n",
    "print(\"获取特征值\")\n",
    "print(fe_cal.data.shape)\n",
    "print('-' * 50)\n",
    "print(fe_cal.data[0])\n",
    "print(\"目标值\")\n",
    "print(fe_cal.target) #单位是10万美金\n",
    "print(fe_cal.DESCR)\n",
    "print('-' * 50)\n",
    "print(fe_cal.feature_names) #特征列的名字"
   ],
   "id": "10f773179b9ef7bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "获取特征值\n",
      "(20640, 8)\n",
      "--------------------------------------------------\n",
      "[   8.3252       41.            6.98412698    1.02380952  322.\n",
      "    2.55555556   37.88       -122.23      ]\n",
      "目标值\n",
      "[4.526 3.585 3.521 ... 0.923 0.847 0.894]\n",
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      ":Number of Instances: 20640\n",
      "\n",
      ":Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      ":Attribute Information:\n",
      "    - MedInc        median income in block group\n",
      "    - HouseAge      median house age in block group\n",
      "    - AveRooms      average number of rooms per household\n",
      "    - AveBedrms     average number of bedrooms per household\n",
      "    - Population    block group population\n",
      "    - AveOccup      average number of household members\n",
      "    - Latitude      block group latitude\n",
      "    - Longitude     block group longitude\n",
      "\n",
      ":Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
      "\n",
      "The target variable is the median house value for California districts,\n",
      "expressed in hundreds of thousands of dollars ($100,000).\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "A household is a group of people residing within a home. Since the average\n",
      "number of rooms and bedrooms in this dataset are provided per household, these\n",
      "columns may take surprisingly large values for block groups with few households\n",
      "and many empty houses, such as vacation resorts.\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. rubric:: References\n",
      "\n",
      "- Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "  Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n",
      "--------------------------------------------------\n",
      "['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "标准化数据",
   "id": "a5ecf25ce7d81801"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T06:15:33.777124Z",
     "start_time": "2025-01-11T06:15:33.766035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(fe_cal.data,fe_cal.target,test_size = 0.25,random_state = 1)\n",
    "std = StandardScaler()\n",
    "x_train = std.fit_transform(x_train)\n",
    "x_test = std.transform(x_test)\n"
   ],
   "id": "597c5cb7c69af750",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "开始回归算法",
   "id": "36de0dd12a6ce87"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T06:26:13.340845Z",
     "start_time": "2025-01-11T06:26:13.324476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(x_train,y_train)\n",
    "\n",
    "#y_predict返回的结果就是每个特征值对结果的影响因子的ndarray\n",
    "y_predict = lr.predict(x_test)\n",
    "print(y_test.shape) #目标值长度与y_predict长度相同\n",
    "print(y_predict)\n",
    "print(\"正规方程测试集里面每个房子的预测价格：\", y_predict[0:10])\n",
    "#下面是求测试集的损失，用均方误差，公式是(y_test-y_predict)^2/n\n",
    "print(\"正规方程的均方误差：\", mean_squared_error(y_test, y_predict))"
   ],
   "id": "2ff6818d5f2fe63d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5160,)\n",
      "[2.12391852 0.93825754 2.7088455  ... 1.24263061 2.73771901 1.75800594]\n",
      "正规方程测试集里面每个房子的预测价格： [2.12391852 0.93825754 2.7088455  1.70873764 2.82954754 3.50376456\n",
      " 3.0147162  1.62781292 1.74317518 2.01897806]\n",
      "正规方程的均方误差： 0.5356532845422556\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "保存模型",
   "id": "97ab9edc3e57657c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "    这个概念第一次涉及，齐用于存储之前训练模型所得的结果（说白了就是这些k值），当然之前的分类算法也可以进行保存\n",
    "    也就解开了如何持续训练模型的答案（增量训练）\n",
    "    \n",
    "    增量训练\n",
    "    不过决策树和随机森林不支持增量训练，只能将新数据和原有数据结合后重新训练\n",
    "    knn和朴素贝叶斯支持增量训练，但是knn由于数据量的增加计算效率会变得非常慢，所以增量会有限\n",
    "    通过   load_model.partial_fit(X_train2, y_train2) \n",
    "\"\"\""
   ],
   "id": "4217f110c5f24de6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "os.unlink('./tmp/test.pkl') # 删除之前的模型文件（这里只是学习如何删除模型文件）\n",
    "joblib.dump(lr, \"./tmp/test.pkl\") # 保存模型\n",
    "load_model = joblib.load('./tmp/test.pkl') #加载模型\n",
    "load_model.partial_fit(X_train2, y_train2) # 增量训练（如果该算法支持增量训练）"
   ],
   "id": "15492fce65e72a9b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 回归算法 2.线性回归（梯度下降版） SGDRegressor()\n",
   "id": "1165152b083c57a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "    用梯度下降来实现线性回归，内部实现是通过迭代优化\n",
    "    对比正规方程版，速度慢，适用于大型数据\n",
    "\"\"\""
   ],
   "id": "cacf7d50730894d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T07:07:31.806771Z",
     "start_time": "2025-01-11T07:07:31.780592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sgd = SGDRegressor()\n",
    "\n",
    "#上面算法1已经处理完数据了，这里直接用\n",
    "sgd.fit(x_train,y_train) \n",
    "y_predict = sgd.predict(x_test)\n",
    "print(\"梯度下降的均方误差：\", mean_squared_error(y_test, y_predict))"
   ],
   "id": "c91ae6472b11d6b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "梯度下降的均方误差： 0.5392029356811116\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 模拟梯度下降的过程",
   "id": "95b37392b2cba05f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "    这段代码展示了一个典型的梯度下降优化过程，用来最小化一个简单的二次损失函数：\n",
    "    1.初始化参数W和α\n",
    "    2.迭代更新梯度，更新参数W\n",
    "    3.损失值L（W）随着迭代次数增加而减少，最终收敛到全局最优点（若是在二次函数中，他总能结束在全局最优）\n",
    "    \n",
    "\n",
    "\"\"\""
   ],
   "id": "46bdcf6ee75bcf60"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T07:19:45.722577Z",
     "start_time": "2025-01-11T07:19:45.715711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "w=1\n",
    "\n",
    "# alpha为学习率，它决定了每次更新的步长。如果学习率过大，可能导致参数跳跃过多，无法收敛；如果学习率过小，收敛速度会很慢。\n",
    "alpha=0.7\n",
    "\n",
    "#损失函数 L(w) \n",
    "def loss(w):\n",
    "    return 2*w**2+3*w+2\n",
    "#导数，也就是L(w)对w的梯度\n",
    "def dao_shu(w):\n",
    "    return 4*w+3\n",
    "\n",
    "#通过w = w - a*梯度 更新w\n",
    "for i in range(30):\n",
    "    \n",
    "    w=w-alpha*dao_shu(w)\n",
    "    print(f'w {w} 损失{loss(w)}')"
   ],
   "id": "85b61903ffc37bda",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w -3.8999999999999995 损失20.71999999999999\n",
      "w 4.919999999999999 损失65.17279999999998\n",
      "w -10.955999999999996 损失209.19987199999983\n",
      "w 17.620799999999992 损失675.8475852799994\n",
      "w -33.817439999999976 损失2187.786176307197\n",
      "w 58.77139199999995 损失7086.4672112353155\n",
      "w -107.8885055999999 损失22958.193764402422\n",
      "w 192.09931007999978 损失74382.58779666382\n",
      "w -347.87875814399956 损失240997.6244611907\n",
      "w 624.0817646591992 损失780830.3432542577\n",
      "w -1125.4471763865586 损失2529888.352143795\n",
      "w 2023.7049174958051 损失8196836.300945894\n",
      "w -3644.768851492449 损失26557747.65506469\n",
      "w 6558.483932686408 损失86047100.4424096\n",
      "w -11807.371078835533 损失278792603.4734071\n",
      "w 21251.167941903957 损失903288033.2938386\n",
      "w -38254.202295427116 损失2926653225.912036\n",
      "w 68855.4641317688 损失9482356449.994993\n",
      "w -123941.93543718383 损失30722834896.023777\n",
      "w 223093.38378693088 损失99541985061.15703\n",
      "w -401570.1908164755 损失322516031596.1886\n",
      "w 722824.2434696557 损失1044951942369.6908\n",
      "w -1301085.73824538 损失3385644293275.837\n",
      "w 2341952.228841684 损失10969487510211.748\n",
      "w -4215516.1119150305 损失35541139533084.09\n",
      "w 7587926.901447055 损失115153292087190.52\n",
      "w -13658270.5226047 损失373096666362495.4\n",
      "w 24584884.840688456 损失1208833199014482.5\n",
      "w -44252794.81323922 损失3916619564806921.0\n",
      "w 79655028.56383058 损失1.268984738997442e+16\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 回归算法 3.岭回归 Ridge()",
   "id": "7b83636865ebf714"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "    岭回归是一种线性回归的扩展，主要用于解决线性回归模型中 多重共线性（即特征之间高度相关）的问题，同时可以抑制模型的过拟合。\n",
    "    \n",
    "    岭回归的目标是引入 L2 正则化 项，修改普通线性回归的损失函数，添加一个对回归系数大小的惩罚项。\n",
    "        在普通的损失函数计算中添加一个L = L + λ*|| w ||2\n",
    "            λ     ：正则化强度\n",
    "        ｜｜w｜｜2 ：所有回归系数的平方和\n",
    "        \n",
    "        \n",
    "\"\"\""
   ],
   "id": "15711575bdeaf347"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T07:29:52.176355Z",
     "start_time": "2025-01-11T07:29:52.171841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rd = Ridge(alpha = 0.02)\n",
    "rd.fit(x_train,y_train)\n",
    "\n",
    "y_predict = rd.predict(x_test)\n",
    "print(rd.coef_)\n",
    "print(\"岭回归的均方误差：\", mean_squared_error(y_test, y_predict))\n"
   ],
   "id": "4cac1b90b3b49cc7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.83166963  0.12159681 -0.26758236  0.30983534 -0.00517992 -0.04040432\n",
      " -0.90735215 -0.88211025]\n",
      "[ 0.83166963  0.12159681 -0.26758236  0.30983534 -0.00517992 -0.04040432\n",
      " -0.90735215 -0.88211025]\n",
      "岭回归的均方误差： 0.5356531179270403\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### L1正则化 Lasso回归\n",
   "id": "8c5667a14e647e96"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "    lasso 回归就是L1正则化，也就是 在普通的损失函数计算中添加一个L = L + λ*|| w ||\n",
    "    也就是岭回归去掉平方\n",
    "    这样做可以实现特征选择：当某些特征对目标值的影响较小时，其对应的回归系数会被直接压缩到 0，从而实现 特征选择。\n",
    "    \n",
    "    优点：1.特征选择能力：Lasso 回归可以自动将不重要的特征对应的回归系数压缩到 0，从而实现特征选择。\n",
    "         2.抑制多重共线性：L1 正则化可以限制特征之间的共线性对模型的影响。\n",
    "         3.简单易用：与普通线性回归相比，Lasso 只增加了一个正则化参数 λ，但增强了模型的泛化能力。\n",
    "    缺点：1.处理特征多于样本时的不足：如果特征数多于样本数（例如高维数据），Lasso 可能会随机选择部分特征作为非零系数。\n",
    "         2.则化参数调试成本高：需要通过交叉验证等方法选择最佳 λ\n",
    "         3.不能很好地处理强相关特征：如果多个特征之间高度相关，Lasso 可能会随机选择其中一个特征而忽略其他特征。\n",
    "\"\"\""
   ],
   "id": "a7e90226111f53b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T07:41:17.982233Z",
     "start_time": "2025-01-11T07:41:17.965715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ls = Lasso(alpha = 0.001)\n",
    "\n",
    "ls.fit(x_train,y_train)\n",
    "y_predict = ls.predict(x_test)\n",
    "print(ls.coef_)\n",
    "print(\"Lasso回归的均方误差：\", mean_squared_error(y_test, y_predict))"
   ],
   "id": "b866f0c41431773c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.82655827  0.1225482  -0.25369194  0.29596304 -0.00381001 -0.03948424\n",
      " -0.89646842 -0.87060253]\n",
      "Lasso回归的均方误差： 0.5356324125105497\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 回归算法 5. 逻辑回归 LogisticRegression()\n",
   "id": "5f46cec6aa54df04"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "    lg = LogisticRegression(C=0.5, solver='lbfgs')\n",
    "        C是正则化参数，他是正则化强度的倒数 C = 1/λ   λ是正则化的超参数，控制模型复杂度。\n",
    "        \n",
    "        solver参数决定了用于训练模型时的优化算法。逻辑回归常用的优化算法有以下几种：\n",
    "            'liblinear':适用于小型数据集，支持 L1 和 L2 正则化。\n",
    "            'lbfgs':适用于大多数中到大型数据集，支持 L2 正则化，通常更稳定，适用于多分类任务。\n",
    "            'newton-cg':适用于大数据集和多分类任务，支持 L2 正则化。\n",
    "            'saga':适用于大数据集，支持 L1 和 L2 正则化，适用于需要 L1 正则化的场景。\n",
    "            \n",
    "\n",
    "    Logistic Regression（逻辑回归） 是一种广泛应用的机器学习算法，主要用于二分类问题。尽管它名字中有“回归”一词，但它实际上是一种分类算法。其核心思想是利用一个线性模型来预测类别概率，并将其转化为类别标签。\n",
    "    \n",
    "    y = σ * ( w1 * x1 + w2 * x2 + ... + b)\n",
    "        y 为类别1 的 概率\n",
    "        w为特征的权重系数\n",
    "        b是偏置值\n",
    "        σ(z) 是sigmod函数  σ(z) = 1 / （1+e的-z次方）\n",
    "        \n",
    "    在训练逻辑回归模型时，目的是最小化损失函数。对于逻辑回归，使用的是 交叉熵损失函数（也叫对数损失函数）。\n",
    "        L(y,y1) = -(y*log(y1) + (1-y)*log(1-y1))\n",
    "            其中y为真实概率\n",
    "            y1为预测概率\n",
    "        整个训练集上的损失函数是所有样本的损失函数总和的平均值\n",
    "        \n",
    "        逻辑回归用的也是梯度下降的方式来训练模型学习参数    \n",
    "    \n",
    "    \n",
    "        \n",
    "\"\"\""
   ],
   "id": "8e140e1d916a7ff2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a7e18e7c3616858a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T10:04:50.424327Z",
     "start_time": "2025-01-13T10:04:50.392222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 构造列标签名字\n",
    "column = ['Sample code number', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape',\n",
    "          'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli',\n",
    "          'Mitoses', 'Class']\n",
    "\n",
    "data = pd.read_csv(\n",
    "    \"../python_ml/data/breast-cancer-wisconsin.csv\",\n",
    "    names=column)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    read_csv如果某一列全是数值型的话读入就会存为数值型，如果不是的话就说明这里列里面有缺失值\n",
    "    \n",
    "    比如：这个数据组里的 6   Bare Nuclei 列看起来都是数据但读入是object\n",
    "\"\"\"\n",
    "#当你读取数据时，看上去是数值的列，读进来是字符串，说明里边\n",
    "# 存在了非数值情况\n",
    "print(data.info())\n",
    "print(data.describe(include='all'))"
   ],
   "id": "ba123282ba8a73ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 11 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   Sample code number           699 non-null    int64 \n",
      " 1   Clump Thickness              699 non-null    int64 \n",
      " 2   Uniformity of Cell Size      699 non-null    int64 \n",
      " 3   Uniformity of Cell Shape     699 non-null    int64 \n",
      " 4   Marginal Adhesion            699 non-null    int64 \n",
      " 5   Single Epithelial Cell Size  699 non-null    int64 \n",
      " 6   Bare Nuclei                  699 non-null    object\n",
      " 7   Bland Chromatin              699 non-null    int64 \n",
      " 8   Normal Nucleoli              699 non-null    int64 \n",
      " 9   Mitoses                      699 non-null    int64 \n",
      " 10  Class                        699 non-null    int64 \n",
      "dtypes: int64(10), object(1)\n",
      "memory usage: 60.2+ KB\n",
      "None\n",
      "        Sample code number  Clump Thickness  Uniformity of Cell Size  \\\n",
      "count         6.990000e+02       699.000000               699.000000   \n",
      "unique                 NaN              NaN                      NaN   \n",
      "top                    NaN              NaN                      NaN   \n",
      "freq                   NaN              NaN                      NaN   \n",
      "mean          1.071704e+06         4.417740                 3.134478   \n",
      "std           6.170957e+05         2.815741                 3.051459   \n",
      "min           6.163400e+04         1.000000                 1.000000   \n",
      "25%           8.706885e+05         2.000000                 1.000000   \n",
      "50%           1.171710e+06         4.000000                 1.000000   \n",
      "75%           1.238298e+06         6.000000                 5.000000   \n",
      "max           1.345435e+07        10.000000                10.000000   \n",
      "\n",
      "        Uniformity of Cell Shape  Marginal Adhesion  \\\n",
      "count                 699.000000         699.000000   \n",
      "unique                       NaN                NaN   \n",
      "top                          NaN                NaN   \n",
      "freq                         NaN                NaN   \n",
      "mean                    3.207439           2.806867   \n",
      "std                     2.971913           2.855379   \n",
      "min                     1.000000           1.000000   \n",
      "25%                     1.000000           1.000000   \n",
      "50%                     1.000000           1.000000   \n",
      "75%                     5.000000           4.000000   \n",
      "max                    10.000000          10.000000   \n",
      "\n",
      "        Single Epithelial Cell Size Bare Nuclei  Bland Chromatin  \\\n",
      "count                    699.000000         699       699.000000   \n",
      "unique                          NaN          11              NaN   \n",
      "top                             NaN           1              NaN   \n",
      "freq                            NaN         402              NaN   \n",
      "mean                       3.216023         NaN         3.437768   \n",
      "std                        2.214300         NaN         2.438364   \n",
      "min                        1.000000         NaN         1.000000   \n",
      "25%                        2.000000         NaN         2.000000   \n",
      "50%                        2.000000         NaN         3.000000   \n",
      "75%                        4.000000         NaN         5.000000   \n",
      "max                       10.000000         NaN        10.000000   \n",
      "\n",
      "        Normal Nucleoli     Mitoses       Class  \n",
      "count        699.000000  699.000000  699.000000  \n",
      "unique              NaN         NaN         NaN  \n",
      "top                 NaN         NaN         NaN  \n",
      "freq                NaN         NaN         NaN  \n",
      "mean           2.866953    1.589413    2.689557  \n",
      "std            3.053634    1.715078    0.951273  \n",
      "min            1.000000    1.000000    2.000000  \n",
      "25%            1.000000    1.000000    2.000000  \n",
      "50%            1.000000    1.000000    2.000000  \n",
      "75%            4.000000    1.000000    4.000000  \n",
      "max           10.000000   10.000000    4.000000  \n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "caa8fc88c85bdb74"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T10:12:26.548758Z",
     "start_time": "2025-01-13T10:12:26.541871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#通过unique函数来看看里面究竟有什么值 （用于大部分的数据都相同的时候）\n",
    "data['Bare Nuclei'].unique()"
   ],
   "id": "a1c87be0f246e963",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 10,  2,  4,  3,  9,  7,  5,  8,  6], dtype=int16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T10:12:57.643446Z",
     "start_time": "2025-01-13T10:12:57.637173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#发现里面有问号，那就把问号转为nan然后直接drop\n",
    "data = data.replace(to_replace='?',value = np.nan)\n",
    "data.dropna(inplace=True)\n",
    "data[column[6]] = data[column[6]].astype('int16')\n",
    "data"
   ],
   "id": "1104f582e647146f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     Sample code number  Clump Thickness  Uniformity of Cell Size  \\\n",
       "0               1000025                5                        1   \n",
       "1               1002945                5                        4   \n",
       "2               1015425                3                        1   \n",
       "3               1016277                6                        8   \n",
       "4               1017023                4                        1   \n",
       "..                  ...              ...                      ...   \n",
       "694              776715                3                        1   \n",
       "695              841769                2                        1   \n",
       "696              888820                5                       10   \n",
       "697              897471                4                        8   \n",
       "698              897471                4                        8   \n",
       "\n",
       "     Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size  \\\n",
       "0                           1                  1                            2   \n",
       "1                           4                  5                            7   \n",
       "2                           1                  1                            2   \n",
       "3                           8                  1                            3   \n",
       "4                           1                  3                            2   \n",
       "..                        ...                ...                          ...   \n",
       "694                         1                  1                            3   \n",
       "695                         1                  1                            2   \n",
       "696                        10                  3                            7   \n",
       "697                         6                  4                            3   \n",
       "698                         8                  5                            4   \n",
       "\n",
       "     Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
       "0              1                3                1        1      2  \n",
       "1             10                3                2        1      2  \n",
       "2              2                3                1        1      2  \n",
       "3              4                3                7        1      2  \n",
       "4              1                3                1        1      2  \n",
       "..           ...              ...              ...      ...    ...  \n",
       "694            2                1                1        1      2  \n",
       "695            1                1                1        1      2  \n",
       "696            3                8               10        2      4  \n",
       "697            4               10                6        1      4  \n",
       "698            5               10                4        1      4  \n",
       "\n",
       "[683 rows x 11 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample code number</th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>776715</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>841769</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>888820</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>683 rows × 11 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "从上面看data，得出第0列没有意义，去除，然后class为目标，也去除，就可以开始喂数据列",
   "id": "3a083f8db64fcb89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T10:35:37.830735Z",
     "start_time": "2025-01-13T10:35:37.818766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(data[column[1:10]],data[column[10]],test_size = 0.25,random_state = 1)\n",
    "\n",
    "#对数据先进行标准化\n",
    "\n",
    "\"\"\"\n",
    "    这里虽然最后数据是喂给logisticRegression的，但是用标准化模型测试数据时也要分别用fit_transform和transform\n",
    "    不然的话对测试集也用fit的话就会造成数据泄露的风险，这里也分开可以提升模型的泛化能力\n",
    "\"\"\"\n",
    "std = StandardScaler()\n",
    "x_train = std.fit_transform(x_train)\n",
    "x_test = std.transform(x_test)\n",
    "\n",
    "lg = LogisticRegression(C=0.5, solver='lbfgs')\n",
    "lg.fit(x_train,y_train)\n",
    "\n",
    "y_predict = lg.predict(x_test)\n",
    "\n",
    "print(lg.coef_)\n",
    "\n",
    "print(\"准确率：\", lg.score(x_test, y_test))\n",
    "\n",
    "# 为什么还要看下召回率，labels和target_names对应\n",
    "# macro avg 平均值  weighted avg 加权平均值\n",
    "\n",
    "\n"
   ],
   "id": "23232c94043cc937",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.11400191 0.25293086 0.78938469 0.60986034 0.0728013  1.10834397\n",
      "  0.7794668  0.64312128 0.67692658]]\n",
      "准确率： 0.9824561403508771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          良性       0.97      1.00      0.99       111\n",
      "          恶性       1.00      0.95      0.97        60\n",
      "\n",
      "    accuracy                           0.98       171\n",
      "   macro avg       0.99      0.97      0.98       171\n",
      "weighted avg       0.98      0.98      0.98       171\n",
      "\n",
      "AUC指标： 0.975\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "    classification_report:是 Scikit-learn 提供的一个非常方便的工具，用于评估分类模型的性能。它输出了包括准确率（precision）、召回率（recall）、F1 值（f1-score）等多项指标的报告，以帮助你全面评估模型的效果。\n",
    "\"\"\"\n",
    "print(classification_report(y_test, y_predict, labels=[2, 4], target_names=[\"良性\", \"恶性\"]))\n",
    "#AUC计算要求是二分类，不需要是0和1\n",
    "print(\"AUC指标：\", roc_auc_score(y_test, y_predict))"
   ],
   "id": "4c4fdd6f6b434c42"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
